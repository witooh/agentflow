import os
import random
import string
from datetime import datetime
from typing import List, Optional, Dict

from fastapi import FastAPI, Request, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel


class RunRequest(BaseModel):
    role: str
    prompt: str
    params: Optional[Dict] = None


class RunResponse(BaseModel):
    runId: str
    content: str


class QuestionsRequest(BaseModel):
    runId: str
    questions: List[str]


class QuestionsResponse(BaseModel):
    status: str = "ok"


app = FastAPI(title="LangGraph Server (Python)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)


def verify_auth(request: Request) -> None:
    """If LANGGRAPH_API_KEY is set, require Authorization: Bearer <key> on non-health endpoints."""
    expected = os.environ.get("LANGGRAPH_API_KEY", "").strip()
    if not expected:
        return
    auth = request.headers.get("Authorization", "").strip()
    if auth != f"Bearer {expected}":
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="unauthorized")


@app.get("/healthz")
def healthz():
    return "ok"


def new_run_id() -> str:
    rand = ''.join(random.choices(string.digits, k=4))
    return f"run_{int(datetime.utcnow().timestamp())}_{rand}"


def synthesize_markdown(role: str, prompt: str) -> str:
    role_title = (role or "agent").upper()
    ts = datetime.utcnow().isoformat()
    parts = [
        "# requirements",
        f"> Generated by LangGraph server ({role_title}) at {ts}",
        "## Goals\n\n- ...",
        "## Scope\n\n- ...",
        "## Functional Requirements (FR)\n\n- ...",
        "## Non-Functional Requirements (NFR)\n\n- ...",
        "## Assumptions\n\n- ...",
        "## Open Questions\n\n- ...",
        "\n<!-- Prompt (echo) -->\n",
        f"```\n{prompt}\n```\n",
    ]
    return "\n".join(parts)


def generate_content(role: str, prompt: str) -> str:
    """Use OpenAI when configured; otherwise fallback to deterministic synthesis."""
    if os.environ.get("OPENAI_API_KEY"):
        try:
            # Import lazily so local dev without openai installed still works
            from openai import OpenAI  # type: ignore
            client = OpenAI()
            model = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
            temperature = float(os.environ.get("OPENAI_TEMPERATURE", "0.2"))
            max_tokens = int(os.environ.get("OPENAI_MAX_TOKENS", "800"))
            messages = [
                {"role": "system", "content": f"You are the {role or 'agent'} in an engineering workflow. Return concise Markdown only."},
                {"role": "user", "content": prompt},
            ]
            resp = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            content = (resp.choices[0].message.content or "").strip()
            if content:
                return content
        except Exception:
            # Fall back to deterministic synthesis on any error
            pass
    return synthesize_markdown(role, prompt)


@app.post("/agents/run", response_model=RunResponse)
async def run_agent(req: RunRequest, request: Request):
    verify_auth(request)
    rid = new_run_id()
    content = generate_content(req.role, req.prompt)
    return RunResponse(runId=rid, content=content)


@app.post("/agents/questions", response_model=QuestionsResponse)
async def ask_questions(req: QuestionsRequest, request: Request):
    verify_auth(request)
    return QuestionsResponse(status="ok")
